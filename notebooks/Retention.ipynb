{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retention\n",
    "### Get a 12 month cohort analysis in a plotly heatmap from a Stripe csv\n",
    "\n",
    "First of all, we open the csv and convert it to a dataframe. Next, we try to match unique user IDs and timestamps for the cohort analysis to work. Then we do a lot of magic for making cohort analyses, as copy and pasted from a tutorial. Finally we get an output plot, which we render inside the jupyter notebook, and export as a json that can be rendered in glint.\n",
    "\n",
    "If the supplied CSV doesn't contain **user ids** and **timestamps** that can be parsed, this notebook will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "# stay offline for plotly -> fixme to ignore?\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# using sample data from https://github.com/thepag/stripe-csv-audit/blob/master/examples/sample.csv\n",
    "file_name = \"../data/sample.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv, if that doesn't work, coerce with latin-1 encoding\n",
    "try:\n",
    "    df = pd.read_csv(file_name)\n",
    "except:\n",
    "    df = pd.read_csv(file_name, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_user_timestamp_columns(df):\n",
    "    \"\"\"Takes in a dataframe, and tries to identify user ids\n",
    "    and timestamps automatically. Returns the names of columns \n",
    "    that appear to match the criteria.\n",
    "    \n",
    "    NOTE: would be amazeballs to put in something like Sherlock\n",
    "    or Sato at this stage to facilitate process.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): an input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        user_id_column (str): likely user id column\n",
    "        timestamp_column (str): likely user id column\"\"\"\n",
    "\n",
    "    # lists of common names for columns\n",
    "    user_columns = ['user', 'client', 'userid', 'clientid', 'user_id', 'client_id', 'client.email', 'customer id']\n",
    "    timestamp_columns = ['timestamp', 'state.openTimestamp', 'datetime', 'created (utc)']\n",
    "\n",
    "    # create empty vars\n",
    "    user_id_column = \"\"\n",
    "    timestamp_column = \"\"\n",
    "\n",
    "    for column in list(df.columns):\n",
    "        if column.lower() in user_columns:\n",
    "            user_id_column = column\n",
    "        elif column.lower() in timestamp_columns:\n",
    "            timestamp_column = column\n",
    "\n",
    "    print(f'Identified \"{user_id_column}\" as user col, \"{timestamp_column}\" as timestamp col')\n",
    "    \n",
    "    return user_id_column, timestamp_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_column, timestamp_column = identify_user_timestamp_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up timestamps and parse out month\n",
    "df['native_timestamp'] = pd.to_datetime(df[timestamp_column], errors='coerce')\n",
    "df['month'] = df['native_timestamp'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create retention dataframe\n",
    "retention = pd.DataFrame({'UserId': df[user_id_column], 'OrderId': df.index, 'OrderPeriod': df['month']})\n",
    "\n",
    "# set the index to customer ids\n",
    "retention.set_index('UserId', inplace=True)\n",
    "\n",
    "# find the first time each customer ordered to get the cohort group\n",
    "retention['CohortGroup'] = retention.groupby(level=0)['OrderPeriod'].min()\n",
    "retention.reset_index(inplace=True)\n",
    "\n",
    "# group by cohort and order period\n",
    "grouped = retention.groupby(['CohortGroup', 'OrderPeriod'])\n",
    "\n",
    "# count the unique users, orders, and total revenue per Group + Period\n",
    "cohorts = grouped.agg({'UserId': pd.Series.nunique,\n",
    "                       'OrderId': pd.Series.nunique})\n",
    "\n",
    "# make the column names more meaningful\n",
    "cohorts.rename(columns={'UserId': 'TotalUsers',\n",
    "                        'OrderId': 'TotalOrders'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohort_period(df):\n",
    "    \"\"\"\n",
    "    Creates a `CohortPeriod` column, which is the Nth period based on the user's first purchase.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    Say you want to get the 3rd month for every user:\n",
    "        df.sort(['UserId', 'OrderTime', inplace=True)\n",
    "        df = df.groupby('UserId').apply(cohort_period)\n",
    "        df[df.CohortPeriod == 3]\n",
    "    \"\"\"\n",
    "    df['CohortPeriod'] = np.arange(len(df)) + 1\n",
    "    return df\n",
    "\n",
    "cohorts = cohorts.groupby(level=0).apply(cohort_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex the DataFrame\n",
    "cohorts.reset_index(inplace=True)\n",
    "cohorts.set_index(['CohortGroup', 'CohortPeriod'], inplace=True)\n",
    "\n",
    "# create a Series holding the total size of each CohortGroup\n",
    "cohort_group_size = cohorts['TotalUsers'].groupby(level=0).first()\n",
    "\n",
    "# unstack cohort\n",
    "user_retention = cohorts['TotalUsers'].unstack(0).divide(cohort_group_size, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take last 12 months for clean plot\n",
    "last_12 = user_retention.T.iloc[-12:]\n",
    "\n",
    "# make it descending for nicer plotly viz\n",
    "last_12 = last_12.sort_index(ascending=False)\n",
    "\n",
    "# remove empty columns\n",
    "last_12 = last_12.dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply by 100 to get the percentage\n",
    "last_12[last_12.select_dtypes(include=['number']).columns] *= 100\n",
    "\n",
    "# round down to 2 decimal places\n",
    "last_12 = np.round(last_12, decimals=2)\n",
    "\n",
    "# drop first column because it's 100%\n",
    "last_12 = last_12.drop(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fig for rendering inside of jupyter notebook\n",
    "colorscale = [[0, 'rgb(255, 255, 255)'],[0.5, 'rgb(227, 0, 6)'], [1, 'rgb(208, 2, 100)']]\n",
    "fig = go.Figure(data=go.Heatmap(z=last_12, y=last_12.index, colorscale=colorscale))\n",
    "fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "fig['layout']['plot_bgcolor'] = 'rgba(0,0,0,0)'\n",
    "\n",
    "fig.update_layout(\n",
    "    title='12 month user retention',\n",
    "    xaxis_title=\"Cohort period\",\n",
    "    yaxis_title=\"Cohort group\",\n",
    "    margin=dict(\n",
    "        pad=10\n",
    "    ),\n",
    "    font=dict(\n",
    "        family=\"-apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', 'Helvetica Neue', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';\",\n",
    "        size=12,\n",
    "        color=\"#7f7f7f\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#EEEEEE')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#EEEEEE')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "output",
     "plotly"
    ]
   },
   "outputs": [],
   "source": [
    "# convert to json\n",
    "output_json = fig.to_json()\n",
    "\n",
    "# apply tweaks by unconverting from jason\n",
    "# (if you don't do this you get an ndarray error)\n",
    "output = json.loads(output_json)\n",
    "output['layout']['template']['data']['table'][0]['cells']['fill']['color'] = \"#FFFFFF\"\n",
    "output['layout']['template']['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "\n",
    "# export for plotly component in glint\n",
    "print(json.dumps(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
